<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>How HTBoost speeds up training with large p · HybridTreeBoosting.jl</title><meta name="title" content="How HTBoost speeds up training with large p · HybridTreeBoosting.jl"/><meta property="og:title" content="How HTBoost speeds up training with large p · HybridTreeBoosting.jl"/><meta property="twitter:title" content="How HTBoost speeds up training with large p · HybridTreeBoosting.jl"/><meta name="description" content="Documentation for HybridTreeBoosting.jl."/><meta property="og:description" content="Documentation for HybridTreeBoosting.jl."/><meta property="twitter:description" content="Documentation for HybridTreeBoosting.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HybridTreeBoosting.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../Parameters/">Parameters</a></li><li><a class="tocitem" href="../../JuliaAPI/">API</a></li><li><a class="tocitem" href="../../Tutorials/">Tutorials (Julia)</a></li><li><a class="tocitem" href="../../Examples/">Examples (Julia)</a></li><li><a class="tocitem" href="../../Tutorials_R/">Tutorials (R)</a></li><li><a class="tocitem" href="../../Tutorials_py/">Tutorials (Python)</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>How HTBoost speeds up training with large p</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>How HTBoost speeds up training with large p</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/PaoloGiordani/HybridTreeBoosting.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/PaoloGiordani/HybridTreeBoosting.jl.git" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="How-HTBoost-speeds-up-training-with-large-p"><a class="docs-heading-anchor" href="#How-HTBoost-speeds-up-training-with-large-p">How HTBoost speeds up training with large p</a><a id="How-HTBoost-speeds-up-training-with-large-p-1"></a><a class="docs-heading-anchor-permalink" href="#How-HTBoost-speeds-up-training-with-large-p" title="Permalink"></a></h1><p><strong>Short description:</strong></p><p>We explore how sparsevs affects speed and accuracy.</p><p><strong>Extensive description:</strong> </p><p>Sparsevs is used by HTBoost to speed up HTBoost with large number of features (p&gt;&gt;100). The idea is to to store, at predetermined intervals (a Fibonacci sequence in default), the  ten (or other number: param.number<em>best</em>features) features that had the lowest loss in each split of the tree. For example, for a tree of depth 4, between 10 and 40 features will be stored in this group of best<em>features at the first update (10 if the same features have the lowest loss at each split). In the next tree, only the features in this group will be considered as candidates for splitting, saving time for large p. At the next predetermined update, the best features are added to this group. Dichotomous features (i.e. dummies, taking only two values) are always included, since much faster. Since features never leave the group of best</em>features, this group can get large if the environment is dense, and will stay small if the environment is sparse. Large speed-ups gains are therefore not guaranteed, but the forecasting accuracy should not be strongly affected except in extreme cases where several hundred features are needed to accurately fit the data. To prevent loss of fit, an automatic warning is issued if the size of the group of best<em>features is over 50% the largest theoretical size (output.ratio</em>actual_max&gt;0.5).</p><p>The speed-ups gains are typically smaller than may be expected, due to the fact that i) parallelization becomes more efficient for larger p<em>/number_workers (where p</em> is the number of candidate features at a given split, and p*&lt;p if sparsevs = :On ), and ii) there is a fixed cost for refineOptim  (refine otimization of μ,τ,m given i). Speed-ups are larger for very large p (e.g. p=2000)</p><pre><code class="language-julia hljs">
number_workers  = 8  # desired number of workers

using Distributed
nprocs()&lt;number_workers ? addprocs( number_workers - nprocs()  ) : addprocs(0)
@everywhere using HybridTreeBoosting

using Random,Statistics
using LightGBM

# USER&#39;S OPTIONS 
Random.seed!(123)

# Options for data generation 
n         = 1_000
p         = 1_000        # number of features 
stde      = 1            

# Options for HTBoost: modality is the key parameter guiding hyperparameter tuning and learning rate.
# :fast and :fastest only fit one model at default parameters, while :compromise and :accurate perform
# automatic hyperparameter tuning. 

sparsevs         = :On
modality         = :compromise   # :accurate, :compromise (default), :fast, :fastest

number_best_features = 10  # Default 10. &lt;10 to consider fewer features in each split (larger speed gains, less precision)
frequency_update     = 1       # Default 1. &gt;1 to update less frequently (larger speed gains, less precision)

nfold            = 1     # 1 for fair comparison with LightGBM
nofullsample     = true  # true for fair comparison with LightGBM

verbose          = :Off
warnings         = :On

ntrees           = 1000   # maximum number of trees 

# function: Friedman of linear, with pstar relevant features.
# Increasing the number of relevant features increases the difficulty of the problem and can be
# used to evaluate speed gains and accuracy losses of sparsevs.

Friedman_function(x) = 10.0*sin.(π*x[:,1].*x[:,2]) + 20.0*(x[:,3].-0.5).^2 + 10.0*x[:,4] + 5.0*x[:,5]

p_star    = 10       # number of relevant features 
β = randn(p_star)
dgp(x)  = x[:,1:length(β)]*β

# END USER&#39;S INPUTS 

if dgp==Friedman_function
    x,x_test = rand(n,p), rand(200_000,p)    # Friedman function on U(0,1)
else 
    x,x_test = randn(n,p), randn(200_000,p)    
end     

f       = dgp(x)
y      = f + stde*randn(n)
f_true = dgp(x_test)

# LightGBM

# Create an estimator with the desired parameters—leave other parameters at the default values.
estimator = LGBMRegression(   # LGBMRegression(...)
    objective = &quot;regression&quot;,
    categorical_feature = [],  # or [1,2,3,5,6,7,8], treating date as a category, as probably Lightgbm would.
    num_iterations = ntrees,   # default 100
    learning_rate = 0.1,      # default 0.1
    early_stopping_round = 50,  # default 0, i.e. Inf
    bagging_fraction = 1.0,
    metric = [&quot;l2&quot;],
    num_threads = number_workers
)

sharevalidation = 0.3
n_train = Int(round((1-sharevalidation)*length(y)))
x_train = x[1:n_train,:]; y_train = y[1:n_train]
x_val   = x[n_train+1:end,:]; y_val = y[n_train+1:end]

LightGBM.fit!(estimator,x_train,y_train,(x_val,y_val),verbosity=-1)
yf_gbm = LightGBM.predict(estimator,x_test)


# HTBoost

param   = HTBparam(modality=modality,ntrees=ntrees,sparsevs=sparsevs,
                    frequency_update=frequency_update,number_best_features=number_best_features,
                    nfold=nfold,verbose=:Off,warnings=:On)

data  = HTBdata(y,x,param)

println(&quot;\n n = $n, p = $p, modality = $modality, sparsevs = $sparsevs, frequency_update = $frequency_update&quot;)
println(&quot; time to fit &quot;)

@time output = HTBfit(data,param);
yf = HTBpredict(x_test,output,predict=:Ey)  # predict

println(&quot;\n RMSE of HTBoost from true E(y|x)                   &quot;, sqrt(mean((yf-f_true).^2)) )
println(&quot; RMSE of LightGBM (default param) from true E(y|x)     &quot;, sqrt(mean((yf_gbm-f_true).^2)) )

fnames,fi,fnames_sorted,fi_sorted,sortedindx = HTBrelevance(output,data,verbose=false);
println(&quot; HTBoost number of included features in final model $(sum(fi.&gt;0))&quot;)

if param.sparsevs == :On
    @info &quot; sparsevs is :On. Repeat with sparsevs=:Off to track speed gains and any accuracy loss. Speed gains will be smaller if many features are relevant.&quot;
else 
    @info &quot; sparsevs is :Off. Repeat with sparsevs=:On to track speed loss and any accuracy gains. Speed gains will be smaller if many features are relevant.&quot;
end     
</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Friday 14 March 2025 14:37">Friday 14 March 2025</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
