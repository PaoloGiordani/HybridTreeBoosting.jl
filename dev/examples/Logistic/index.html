<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Logistic regression for binary classification · HybridTreeBoosting.jl</title><meta name="title" content="Logistic regression for binary classification · HybridTreeBoosting.jl"/><meta property="og:title" content="Logistic regression for binary classification · HybridTreeBoosting.jl"/><meta property="twitter:title" content="Logistic regression for binary classification · HybridTreeBoosting.jl"/><meta name="description" content="Documentation for HybridTreeBoosting.jl."/><meta property="og:description" content="Documentation for HybridTreeBoosting.jl."/><meta property="twitter:description" content="Documentation for HybridTreeBoosting.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">HybridTreeBoosting.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><a class="tocitem" href="../../Parameters/">Parameters</a></li><li><a class="tocitem" href="../../JuliaAPI/">API</a></li><li><a class="tocitem" href="../../Tutorials/">Tutorials (Julia)</a></li><li><a class="tocitem" href="../../Examples/">Examples (Julia)</a></li><li><a class="tocitem" href="../../Tutorials_R/">Tutorials (R)</a></li><li><a class="tocitem" href="../../Tutorials_py/">Tutorials (Python)</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Logistic regression for binary classification</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Logistic regression for binary classification</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/PaoloGiordani/HybridTreeBoosting.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/PaoloGiordani/HybridTreeBoosting.jl.git" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Logistic-regression-for-binary-classification"><a class="docs-heading-anchor" href="#Logistic-regression-for-binary-classification">Logistic regression for binary classification</a><a id="Logistic-regression-for-binary-classification-1"></a><a class="docs-heading-anchor-permalink" href="#Logistic-regression-for-binary-classification" title="Permalink"></a></h1><p><strong>Short description:</strong></p><ul><li>Comparison with lightGBM on a logistic regression problem with simulated data.</li><li>param.modality as the most important user&#39;s choice.</li><li>In default modality, HTBoost performs automatic hyperparameter tuning.</li></ul><p><strong>Extensive description:</strong> </p><p>Sketch of a comparison of HTBoost and lightGBM on a logistic regression problem. The comparison with LightGBM is biased toward HTBoost if the function generating the data is  smooth in some features (this is easily changed by the user). lightGBM is cross-validated over max<em>depth and num</em>leaves, with the number of trees set to 1000 and found by early stopping.</p><p>Options for HTBoost: modality is the key parameter guiding hyperparameter tuning and learning rate. :fast and :fastest only fit one model at default parameters, while :compromise and :accurate perform automatic hyperparameter tuning. In HTBoost, it is not recommended that the user performs  hyperparameter tuning by cross-validation, because this process is done automatically if modality is :compromise or :accurate. The recommended process is to first run in modality=:fast or :fastest, for exploratory analysis and to gauge computing time, and then switch to :compromise (default) or :accurate.</p><pre><code class="language-julia hljs">
number_workers  = 8  # desired number of workers

using Distributed
nprocs()&lt;number_workers ? addprocs( number_workers - nprocs()  ) : addprocs(0)
@everywhere using HybridTreeBoosting

using Random,Statistics
using LightGBM

# USER&#39;S OPTIONS 

Random.seed!(1)

# Options for data generation 
n         = 10_000
p         = 10      # mumber of features. p&gt;=4. Only the first 4 variables are used in the function f(x) below 
nsimul    = 1       # number of simulated datasets. 

# Options for HTBoost: modality is the key parameter guiding hyperparameter tuning and learning rate.
# :fast and :fastest only fit one model at default parameters, while :compromise and :accurate perform
# automatic hyperparameter tuning. 

modality  = :fast   # :accurate, :compromise (default), :fast, :fastest

# define the function f(x), where x are indendent N~(0,1), and f(x) is for the natural parameter,
# so f(x) = log(prob/(1-prob))

f_1(x,b)    = b*x .+ 1 
f_2(x,b)    = sin.(b*x)  
f_3(x,b)    = b*x.^2
f_4(x,b)    = b./(1.0 .+ (exp.(5*(x .- 0.5) )))   

b1,b2,b3,b4 = 1.5,2.0,0.5,2.0
dgp(x)        = f_1(x[:,1],b1) + f_2(x[:,2],b2) + f_3(x[:,3],b3) + f_4(x[:,4],b4)
 
# END USER&#39;S OPTIONS  

function simul_logistic(n,p,nsimul,modality,dgp)

 n_test = 100_000
 loss = :logistic

 # initialize containers and parameters for HTBoost and lightGBM
 MSE1 = zeros(nsimul)
 MSE2 = zeros(nsimul)

 param  = HTBparam(loss=loss,nfold=1,nofullsample=true,modality=modality,warnings=:Off,newton_gauss_approx =true)

 # Create an estimator with the desired parameters—leave other parameters at the default values.
 estimator = LGBMClassification(   # LGBMRegression(...)
    objective = &quot;binary&quot;,
    num_class = 1,
    categorical_feature = Int[],
    num_iterations = 1000,
    learning_rate = 0.1,
    early_stopping_round = 100,
    metric = [&quot;binary_logloss&quot;],
    num_threads = number_workers,
    device_type=&quot;cpu&quot;
 )

 for simul in 1:nsimul

    # generate data
    x,x_test = randn(n,p), randn(n_test,p)
    ftrue       = dgp(x)
    ftrue_test  = dgp(x_test)

    y = (exp.(ftrue)./(1.0 .+ exp.(ftrue))).&gt;rand(n) 
    data   = HTBdata(y,x,param)

    output = HTBfit(data,param)
   yf     = HTBpredict(x_test,output,predict=:Egamma)  # predict the natural parameter (only with simulated data; typically we&#39;ll want to predict=:Ey (default))
   MSE1[simul]    = sum((yf - ftrue_test).^2)/n_test

    # lightGBM
    y       = Float64.(y)                 
    n_train = Int(round((1-param.sharevalidation)*length(y)))
    x_train = x[1:n_train,:]; y_train = Float64.(y[1:n_train])
    x_val   = x[n_train+1:end,:]; y_val = Float64.(y[n_train+1:end])
    
   # parameter search over num_leaves and max_depth
   splits = (collect(1:n_train),collect(1:min(n_train,100)))  # goes around the problem that at least two training sets are required by search_cv (we want the first)

   params = [Dict(:num_leaves =&gt; num_leaves,
               :max_depth =&gt; max_depth) for
          num_leaves in (4,16,32,64,127,256),
          max_depth in (2,3,5,6,8)]

   lightcv = LightGBM.search_cv(estimator,x,y,splits,params,verbosity=-1)

   loss_cv = [lightcv[i][2][&quot;validation&quot;][estimator.metric[1]][1] for i in eachindex(lightcv)]
   minind = argmin(loss_cv)

   estimator.num_leaves = lightcv[minind][1][:num_leaves]
   estimator.max_depth  = lightcv[minind][1][:max_depth]

   # fit at cv parameters
   LightGBM.fit!(estimator,x_train,y_train,(x_val,y_val),verbosity=-1)

    yf_gbm = LightGBM.predict(estimator,x_test)[:,1]
    yf_gbm = log.(yf_gbm./(1.0 .- yf_gbm))

    MSE2[simul]    = sum((yf_gbm - ftrue_test).^2)/n_test


 end     

 return MSE1,MSE2

end 


MSE1,MSE2 = simul_logistic(n,p,nsimul,modality,dgp)

println(&quot;\n n = $n, p = $p, number of simulations = $nsimul, modality = $modality&quot;)
println(&quot; avg out-of-sample RMSE from true natural parameter, HTBoost    &quot;, sqrt(mean(MSE1)) )
println(&quot; avg out-of-sample RMSE from true natural parameter, lightGBM      &quot;, sqrt(mean(MSE2)) )
</code></pre></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Friday 14 March 2025 09:06">Friday 14 March 2025</span>. Using Julia version 1.6.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
